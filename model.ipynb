{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5V1f907Zv1f",
        "outputId": "bc8d111c-de9e-402e-ad67-46c51365b5ea"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/Sherlock Holmes.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n"
      ],
      "metadata": {
        "id": "0nAKr5JHZ0yd"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = text.lower()\n",
        "text = re.sub(r'[^a-z\\s]', '', text)\n"
      ],
      "metadata": {
        "id": "_5YyZdbVZ1eB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text.split()\n",
        "print(\"Total words:\", len(tokens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6wxjVPCZ31b",
        "outputId": "979c5567-89d5-4216-faf9-7c52cc86568d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words: 104432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "counter = Counter(tokens)\n",
        "\n",
        "vocab = {\"<UNK>\": 0}\n",
        "for word in counter:\n",
        "    vocab[word] = len(vocab)\n",
        "\n",
        "idx2word = {i: w for w, i in vocab.items()}\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "print(\"Vocab size:\", vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to0W5jizZ5_A",
        "outputId": "47831088-ffe4-46de-a70d-e3e40790ad2d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 8338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = [vocab[word] for word in tokens]\n"
      ],
      "metadata": {
        "id": "G1QayHPTZ8gw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 4\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(len(encoded) - SEQ_LEN):\n",
        "    X.append(encoded[i:i+SEQ_LEN])\n",
        "    y.append(encoded[i+SEQ_LEN])\n"
      ],
      "metadata": {
        "id": "W5aVdrUXaCIC"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class NextWordDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n"
      ],
      "metadata": {
        "id": "sCo61vbnaK4B"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataset = NextWordDataset(X, y)\n",
        "\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "hacplSx7aNRj"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class NextWordModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        out, _ = self.lstm(x)\n",
        "        out = out[:, -1, :]\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "XJE5bfaoaRO9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBED_DIM = 100\n",
        "HIDDEN_DIM = 128\n",
        "\n",
        "model = NextWordModel(vocab_size, EMBED_DIM, HIDDEN_DIM).to(device)\n"
      ],
      "metadata": {
        "id": "8doxyW5taTK0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "qe1ZxECgaV7b"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for x_batch, y_batch in loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {total_loss/len(loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ-Urg9KaXx1",
        "outputId": "8e192f37-e91d-4348-de90-d406e9497e7e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Loss: 6.2016\n",
            "Epoch 2/5 | Loss: 5.4121\n",
            "Epoch 3/5 | Loss: 5.0101\n",
            "Epoch 4/5 | Loss: 4.6714\n",
            "Epoch 5/5 | Loss: 4.3650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Save model weights\n",
        "torch.save(model.state_dict(), \"nextword_model.pt\")\n",
        "\n",
        "# Save vocab dictionary\n",
        "with open(\"vocab.pkl\", \"wb\") as f:\n",
        "    pickle.dump(vocab, f)\n",
        "\n",
        "# Save reverse vocab\n",
        "with open(\"idx2word.pkl\", \"wb\") as f:\n",
        "    pickle.dump(idx2word, f)\n",
        "print(\"Files saved: nextword_model.pt, vocab.pkl, idx2word.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oagmnYMboae",
        "outputId": "95e35113-b883-48e4-98f8-3f98df30ca8a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files saved: nextword_model.pt, vocab.pkl, idx2word.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(text):\n",
        "    model.eval()\n",
        "\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    words = text.split()[-SEQ_LEN:]\n",
        "\n",
        "    if len(words) < SEQ_LEN:\n",
        "        return \"Not enough context\"\n",
        "\n",
        "    encoded = torch.tensor([[vocab[w] for w in words]]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(encoded)\n",
        "        pred_idx = output.argmax(dim=1).item()\n",
        "\n",
        "    return idx2word[pred_idx]\n"
      ],
      "metadata": {
        "id": "ooTinYwtahXU"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_next_word(\"to sherlock holmes\"))\n",
        "print(predict_next_word(\"he was a man\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKuXfKe3ah58",
        "outputId": "d45cac18-4c0e-40e3-b3d2-2fa79eddf767"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not enough context\n",
            "of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MzewBjQzaj4R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}